{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMD EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from model.dmd import (\n",
    "    DRIVER_SESSION_MAPPING,\n",
    "    ROOT,\n",
    "    get_frame_paths,\n",
    ")\n",
    "from model.fonts import set_cmu_serif_font\n",
    "from model.memory_map import MemMapReader\n",
    "\n",
    "set_cmu_serif_font()\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = defaultdict(dict)\n",
    "\n",
    "for driver, sessions in DRIVER_SESSION_MAPPING.items():\n",
    "    for session in sessions:\n",
    "        session = ROOT / session\n",
    "        data[driver][session.name + '_normal'] = len(\n",
    "            get_frame_paths(session, 'normal', 'rgb', 'jpg')\n",
    "        )\n",
    "        data[driver][session.name + '_anomal'] = len(\n",
    "            get_frame_paths(session, 'anomal', 'rgb', 'jpg')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = defaultdict(dict)\n",
    "\n",
    "for driver, driver_data in data.items():\n",
    "    for session, frames in driver_data.items():\n",
    "        if 's1' in session:\n",
    "            if 'normal' in session:\n",
    "                table_data[driver]['test_normal'] = frames\n",
    "            else:\n",
    "                table_data[driver]['test_anomal'] = frames\n",
    "        else:\n",
    "            if 'normal' in session:\n",
    "                if 'train_normal' in table_data[driver]:\n",
    "                    table_data[driver]['train_normal'] += frames\n",
    "                else:\n",
    "                    table_data[driver]['train_normal'] = frames\n",
    "            else:\n",
    "                pass\n",
    "                # if 'train_anomal' in table_data[driver]:\n",
    "                #     table_data[driver]['train_anomal'] += frames\n",
    "                # else:\n",
    "                #     table_data[driver]['train_anomal'] = frames\n",
    "\n",
    "table_data_tab = {}\n",
    "table_data_tab[''] = [\n",
    "    'Train samples',\n",
    "    'Test negative samples',\n",
    "    'Test positive samples',\n",
    "]\n",
    "for driver, driver_data in table_data.items():\n",
    "    frames = [\n",
    "        driver_data['train_normal'],\n",
    "        driver_data['test_normal'],\n",
    "        driver_data['test_anomal'],\n",
    "    ]\n",
    "    table_data_tab[f'Driver {driver}'] = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table_data_tab)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to LaTeX\n",
    "output_dir = Path('outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "df.to_latex(\n",
    "    output_dir / 'dmd_stats.tex',\n",
    "    index=False,\n",
    "    caption=r'Information about train-test split for DMD drivers from group A. Session \\texttt{s1} is used for testing, while the rest are used for training.',\n",
    "    label='tab:dmd-stats',\n",
    "    position='htb',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel Realsense Depth Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = (\n",
    "    ROOT\n",
    "    / 'gA_1_s1_2019-03-08T09;31;15+01;00'\n",
    "    / 'gA_1_s1_2019-03-08T09;31;15+01;00_depth_body.avi'\n",
    ")\n",
    "assert input_video_path.exists()\n",
    "\n",
    "cap = cv2.VideoCapture(str(input_video_path))\n",
    "cap.set(cv2.CAP_PROP_CONVERT_RGB, 0)  # Disable RGB conversion\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 521)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "print(frame.min(), frame.max(), frame.dtype, frame.shape)\n",
    "\n",
    "# Define the threshold (e.g. 2000 mm for 2 meters)\n",
    "depth_threshold = 2000\n",
    "\n",
    "# Clip the depth values so that any value above the threshold is set to the threshold\n",
    "# img_clipped = np.clip(frame, 0, depth_threshold)\n",
    "img_clipped = np.where(frame > depth_threshold, 0, frame)\n",
    "\n",
    "# Map the range [0, depth_threshold] to [0, 255]\n",
    "img8 = ((img_clipped / depth_threshold) * 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.imshow(img8, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def tick_formatter(x: Any, pos: Any) -> str:\n",
    "    \"\"\"Formatter function that scales tick values from 0-255 to 0-2000\"\"\"\n",
    "    return f'{int(round(x * depth_threshold / 255))}'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.imshow(img8, cmap=plt.cm.inferno)  # type: ignore\n",
    "\n",
    "cbar = plt.colorbar(shrink=0.75)\n",
    "cbar.ax.yaxis.set_major_formatter(FuncFormatter(tick_formatter))\n",
    "vmin, vmax = cbar.mappable.get_clim()\n",
    "ticks = np.linspace(vmin, vmax, 8)\n",
    "cbar.set_ticks(ticks)  # type: ignore\n",
    "cbar.set_label('Depth (mm)', rotation=270, labelpad=30)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    output_dir / 'dmd-depth-sensor.pdf',\n",
    "    bbox_inches='tight',\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of Image Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ROOT / 'gA_1_s1_2019-03-08T09;31;15+01;00/anomal/sequence_2/memory_maps'\n",
    "output_dir = Path('outputs/source_types')\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_depth = MemMapReader(data_path / 'depth_64.dat', (64, 64))\n",
    "reader_rgb = MemMapReader(data_path / 'rgb_64.dat', (64, 64, 3))\n",
    "reader_mask = MemMapReader(data_path / 'masks_64.dat', (64, 64))\n",
    "reader_sensor = MemMapReader(data_path / 'source_depth_64.dat', (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_path = data_path.parent / 'crop_rgb' / '000521.jpg'\n",
    "original_image = cv2.imread(str(original_image_path))\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "original_image = cv2.resize(original_image, (512, 512))\n",
    "original_image = original_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image = reader_depth[0]\n",
    "rgb_image = reader_rgb[0]\n",
    "mask_image = reader_mask[0]\n",
    "sensor_image = reader_sensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, gray, name in zip(\n",
    "    [\n",
    "        original_image,\n",
    "        mask_image,\n",
    "        depth_image,\n",
    "        sensor_image,\n",
    "        rgb_image,\n",
    "    ],\n",
    "    [False, True, True, True, False],\n",
    "    ['original', 'mask', 'depth', 'depth_sensor', 'rgb'],\n",
    "    strict=True,\n",
    "):\n",
    "    img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(\n",
    "        img,\n",
    "        cmap='gray' if gray else None,\n",
    "    )\n",
    "    plt.axis('off')\n",
    "    plt.imsave(\n",
    "        output_dir / f'{name}.png',\n",
    "        img,\n",
    "        cmap='gray' if gray else None,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
