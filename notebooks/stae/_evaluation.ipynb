{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of STAE Experiments\n",
    "\n",
    "This notebook connects to MLflow, downloads all experiment runs and creates visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.fonts import set_cmu_typewriter_font\n",
    "from model.plot import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_NAME = 'driver-stae'\n",
    "USER_NAME = 'matejfric'\n",
    "dagshub.init(REPO_NAME, USER_NAME, mlflow=True)  # type: ignore\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "font = set_cmu_typewriter_font()\n",
    "plt.rc('font', size=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all experiment runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = client.search_experiments()\n",
    "pprint([experiment.name for experiment in experiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all runs from the experiments\n",
    "all_runs = []\n",
    "for experiment in experiments:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string='',\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    )\n",
    "    all_runs.extend(runs)\n",
    "\n",
    "# Create a DataFrame from the runs\n",
    "runs_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'run_id': r.info.run_id,\n",
    "            'experiment_id': r.info.experiment_id,\n",
    "            'experiment_name': client.get_experiment(r.info.experiment_id).name,\n",
    "            'status': r.info.status,\n",
    "            'start_time': pd.to_datetime(r.info.start_time, unit='ms'),\n",
    "            'end_time': pd.to_datetime(r.info.end_time, unit='ms')\n",
    "            if r.info.end_time\n",
    "            else None,\n",
    "            'artifact_uri': r.info.artifact_uri,\n",
    "            **r.data.params,  # Add all parameters\n",
    "            **{\n",
    "                f'metric.{k}': v for k, v in r.data.metrics.items()\n",
    "            },  # Add all metrics with \"metric.\" prefix\n",
    "        }\n",
    "        for r in all_runs\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(f'Total runs: {len(runs_df)}')\n",
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_columns = ['image_size', 'batch_size', 'early_stopping']\n",
    "runs_df[integer_columns] = runs_df[integer_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = runs_df[runs_df['image_size'] == 64]\n",
    "runs_df['source_type'] = runs_df['source_type'].fillna('depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = runs_df.groupby(['driver', 'source_type', 'image_size'])[\n",
    "    'metric.roc_auc'\n",
    "].idxmax()\n",
    "best_runs_df = runs_df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = best_runs_df[best_runs_df['image_size'] == 64]\n",
    "df[\n",
    "    [\n",
    "        'driver',\n",
    "        'source_type',\n",
    "        'metric.roc_auc',\n",
    "        'metric.pr_auc',\n",
    "        'early_stopping',\n",
    "        'patience',\n",
    "        'best_metric',\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(local_path=None)\n",
    "local_root = Path.cwd() / 'outputs' / 'mlflow_artifacts'\n",
    "artifact_dir = 'outputs/'\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    run_id = row['run_id']\n",
    "    # Download artifacts and store the path\n",
    "    local_dir = local_root / str(run_id)\n",
    "    local_dir.mkdir(parents=True, exist_ok=True)\n",
    "    local_path = client.download_artifacts(\n",
    "        run_id, artifact_dir + 'predictions.json', str(local_dir)\n",
    "    )\n",
    "    # Save the local path to the dataframe\n",
    "    df.at[index, 'local_path'] = local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type_map = {\n",
    "    'masks': 'Mask',\n",
    "    'depth': 'Depth',\n",
    "    'images': 'RGB',\n",
    "    'rgbd': 'RGBD',\n",
    "    'rgbdm': 'RGBDM',\n",
    "}\n",
    "source_type_color_map = {\n",
    "    'Mask': 'tab:orange',\n",
    "    'Depth': 'tab:blue',\n",
    "    'RGB': 'tab:green',\n",
    "    'RGBD': 'tab:red',\n",
    "    'RGBDM': 'tab:purple',\n",
    "}\n",
    "source_type_linestyle_map = {\n",
    "    'Mask': '-',\n",
    "    'Depth': '--',\n",
    "    'RGB': '-.',\n",
    "    'RGBD': ':',\n",
    "    'RGBDM': '-',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions from the local paths\n",
    "data = defaultdict(dict)\n",
    "for index, row in df.iterrows():\n",
    "    with open(row['local_path']) as f:\n",
    "        results = json.load(f)\n",
    "    data[row['driver']][source_type_map[row['source_type']]] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = list(data.keys())\n",
    "source_types = list(data[list(data.keys())[0]].keys())\n",
    "pprint(source_types)\n",
    "pprint(drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_name_mapping = {'dans': 1, 'geordi': 2, 'jakub': 3, 'michal': 4, 'poli': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = dict(\n",
    "    source_type_color_map=source_type_color_map,\n",
    "    source_type_linestyle_map=source_type_linestyle_map,\n",
    "    driver_name_mapping=driver_name_mapping,\n",
    "    linewidth=3,\n",
    "    legend_outside=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('roc', data, save_path='outputs/roc_auc.pdf', **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('pr', data, save_path='outputs/pr_auc.pdf', **plot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from model.eval import compute_best_roc_auc\n",
    "\n",
    "redata = defaultdict(dict)\n",
    "\n",
    "for driver in drivers:\n",
    "    for source_type in source_types:\n",
    "        x = copy.deepcopy(data[driver][source_type])\n",
    "        res = compute_best_roc_auc(x['y_true'], x['errors'], (0.00, 0.95))\n",
    "        redata[driver][source_type] = x\n",
    "        redata[driver][source_type].update(res)\n",
    "        y = redata[driver][source_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('roc', redata, save_path='outputs/roc_auc_iqr.pdf', **plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('pr', redata, save_path='outputs/pr_auc_iqr.pdf', **plot_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
