{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver State Anomaly Detection With STAE\n",
    "\n",
    "[https://dagshub.com/matejfric/driver-state](https://dagshub.com/matejfric/driver-state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Literal, cast\n",
    "\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import onnx\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torchview\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "# Pytorch Lightning EarlyStopping callback does not recover the best weights as in Keras!\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# https://github.com/Lightning-AI/pytorch-lightning/discussions/10399,\n",
    "# https://pytorch-lightning.readthedocs.io/en/1.5.10/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from model.ae import evaluate_model_parallel, summarize_model\n",
    "from model.ae.temporal_3d import RegularizationType, STAEModel\n",
    "from model.common import Anomalies, BatchSizeDict\n",
    "from model.dataset import STAEDataset, TemporalAutoencoderDatasetDMD\n",
    "from model.dmd import DRIVER_SESSION_MAPPING\n",
    "from model.eval import compute_best_roc_auc\n",
    "from model.fonts import set_cmu_serif_font\n",
    "from model.git import get_commit_id, get_current_branch\n",
    "from model.logging import (\n",
    "    get_early_stopping_epoch,\n",
    "    get_submodule_param_count,\n",
    "    log_dict_to_mlflow,\n",
    ")\n",
    "from model.plot import (\n",
    "    plot_error_and_anomalies,\n",
    "    plot_learning_curves,\n",
    "    plot_pr_chart,\n",
    "    plot_roc_chart,\n",
    "    plot_temporal_autoencoder_reconstruction,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "set_cmu_serif_font()\n",
    "\n",
    "# Experiment logging\n",
    "REPO_NAME = 'driver-stae'\n",
    "USER_NAME = 'matejfric'\n",
    "dagshub.init(REPO_NAME, USER_NAME, mlflow=True)  # type: ignore\n",
    "\n",
    "# Reproducibility\n",
    "# https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "SEED = 42\n",
    "L.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(\n",
    "    f'torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, lightning: {L.__version__}'  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "driver = None\n",
    "source_type = None\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# ----------------------------------------\n",
    "MAX_EPOCHS = 100\n",
    "MIN_EPOCHS = 10\n",
    "MIN_DELTA = 5e-5  # Minimum change of valid loss to qualify as an improvement\n",
    "MONITOR = 'valid_total_loss'\n",
    "PATIENCE = 7\n",
    "# Run memory map script to use different image size (`run_memory_map_conversion.py`)\n",
    "IMAGE_SIZE: Literal[64, 128, 224, 256] = 64\n",
    "BATCH_SIZE = 64\n",
    "SEQUENCE_LENGTH = 16\n",
    "TIME_STEP = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "LAMBDA_REG = 1e-4 if not (dataset == 'dmd' and source_type == 'masks') else 1e-6\n",
    "TRAIN_SET_RATIO = 0.9\n",
    "USE_MASK = True\n",
    "USE_2D_BOTTLENECK: list[int] | None = [64, 128]\n",
    "USE_EXTRA_3DCONV = True\n",
    "REGULARIZATION: RegularizationType | None = 'l2_model_weights'\n",
    "USE_PREDICTION_BRANCH = True\n",
    "SOURCE_TYPE = source_type or 'depth'\n",
    "if SOURCE_TYPE == 'images' or SOURCE_TYPE == 'rgb':\n",
    "    CHANNELS = 3\n",
    "elif SOURCE_TYPE == 'rgbd' or SOURCE_TYPE == 'rgb_source_depth':\n",
    "    CHANNELS = 4\n",
    "elif SOURCE_TYPE == 'rgbdm':\n",
    "    CHANNELS = 5\n",
    "else:\n",
    "    CHANNELS = 1\n",
    "TIME_DIM_INDEX = 1\n",
    "\n",
    "# LOGGING\n",
    "# ----------------------------------------\n",
    "DRIVER_MAP = {\n",
    "    'geordi': '2021_08_31_geordi_enyaq',\n",
    "    'poli': '2021_09_06_poli_enyaq',\n",
    "    'michal': '2021_11_05_michal_enyaq',\n",
    "    'dans': '2021_11_18_dans_enyaq',\n",
    "    'jakub': '2021_11_18_jakubh_enyaq',\n",
    "}\n",
    "NOW = datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "DRIVER = driver or 'geordi'\n",
    "EXPERIMENT_NAME = DRIVER if isinstance(DRIVER, str) else f'driver_{DRIVER}'\n",
    "LOG_DIR = Path('logs')\n",
    "RUN_NAME = f'STAE-{DRIVER}-{SOURCE_TYPE}-{IMAGE_SIZE}x{IMAGE_SIZE}'\n",
    "VERSION = 0\n",
    "EXPERIMENT_DIR = LOG_DIR / f'{NOW}-{RUN_NAME}' / f'version_{VERSION}'\n",
    "\n",
    "# ARTIFACTS\n",
    "# ----------------------------------------\n",
    "MLFLOW_ARTIFACT_DIR = 'outputs'\n",
    "METRICS_CSV_NAME = 'metrics.csv'\n",
    "LEARNING_CURVES_PDF_NAME = 'learning_curves.pdf'\n",
    "PREDICTIONS_NAME = 'predictions.pdf'\n",
    "TRAIN_TRANSFORMS_JSON_NAME = 'train_transforms.json'\n",
    "NOTEBOOK_NAME = 'train.ipynb'\n",
    "ARCHITECTURE_VISUALIZATION_NAME = 'architecture'\n",
    "MODEL_SUMMARY_NAME = 'model_summary.txt'\n",
    "ROC_CHART_NAME = 'roc_chart.pdf'\n",
    "MODEL_ONNX_NAME = 'model.onnx'\n",
    "ERROR_CHART_NAME = 'error_chart.pdf'\n",
    "PR_CHART_NAME = 'pr_chart.pdf'\n",
    "PREDICTIONS_JSON_NAME = 'predictions.json'\n",
    "\n",
    "# DATASET\n",
    "# ----------------------------------------\n",
    "DATASET: Literal['mrl', 'dmd'] = dataset or 'mrl'\n",
    "DATASET_NAME = '2024-10-28-driver-all-frames' if DATASET == 'mrl' else 'dmd'\n",
    "DATASET_DIR = Path().home() / f'source/driver-dataset/{DATASET_NAME}'\n",
    "assert DATASET_DIR.exists(), f'Dataset directory does not exist: {DATASET_DIR}'\n",
    "\n",
    "if DATASET == 'mrl':\n",
    "    driver_dir = DRIVER_MAP[DRIVER]\n",
    "    root_dir = DATASET_DIR / driver_dir\n",
    "    memory_map_filename = (\n",
    "        f'{SOURCE_TYPE}_{IMAGE_SIZE}{\"\" if USE_MASK else \"_no_mask\"}.dat'\n",
    "    )\n",
    "    NORMAL_MEMORY_MAP = root_dir / 'normal' / 'memory_maps' / memory_map_filename\n",
    "    ANOMAL_MEMORY_MAP = root_dir / 'anomal' / 'memory_maps' / memory_map_filename\n",
    "    ANOMALIES_FILE = root_dir / 'anomal' / 'labels.txt'\n",
    "\n",
    "    assert NORMAL_MEMORY_MAP.exists(), (\n",
    "        f'Normal memory map does not exist: {NORMAL_MEMORY_MAP}'\n",
    "    )\n",
    "    assert ANOMAL_MEMORY_MAP.exists(), (\n",
    "        f'Anomal memory map does not exist: {ANOMAL_MEMORY_MAP}'\n",
    "    )\n",
    "    assert ANOMALIES_FILE.exists(), f'Anomalies file does not exist: {ANOMALIES_FILE}'\n",
    "\n",
    "elif DATASET == 'dmd':\n",
    "    TRAIN_SESSIONS = sorted(DRIVER_SESSION_MAPPING[DRIVER])\n",
    "\n",
    "    # Use session 's1' for testing.\n",
    "    DMD_TEST_SESSION = 's1'\n",
    "    TEST_SESSIONS = [x for x in TRAIN_SESSIONS if DMD_TEST_SESSION in x]\n",
    "    TRAIN_SESSIONS = [x for x in TRAIN_SESSIONS if DMD_TEST_SESSION not in x]\n",
    "    assert all(s not in TEST_SESSIONS for s in TRAIN_SESSIONS), (\n",
    "        'Training session(s) cannot be in the test set!'\n",
    "    )\n",
    "\n",
    "    TRAIN_DATASETS = sorted(\n",
    "        [DATASET_DIR / session / 'normal' for session in TRAIN_SESSIONS]\n",
    "    )\n",
    "    assert all(dataset.exists() for dataset in TRAIN_DATASETS), (\n",
    "        'Training datasets do not exist!'\n",
    "    )\n",
    "\n",
    "    TEST_DATASETS = sorted(\n",
    "        [DATASET_DIR / session / 'memory_maps' for session in TEST_SESSIONS]\n",
    "    )\n",
    "    assert all(dataset.exists() for dataset in TEST_DATASETS), (\n",
    "        'Test datasets do not exist!'\n",
    "    )\n",
    "\n",
    "    ANOMALIES_FILES = [\n",
    "        dataset.parent / f'{dataset.parent.name}.json'\n",
    "        for dataset in TEST_DATASETS\n",
    "        if dataset.is_dir()\n",
    "    ]\n",
    "    assert all(anom_file.exists() for anom_file in ANOMALIES_FILES), (\n",
    "        f'Anomalies file does not exist: {ANOMALIES_FILES}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dict = BatchSizeDict(\n",
    "    {'train': BATCH_SIZE, 'valid': BATCH_SIZE, 'test': BATCH_SIZE}\n",
    ")\n",
    "\n",
    "if DATASET == 'dmd':\n",
    "    train_val_dataset = TemporalAutoencoderDatasetDMD(\n",
    "        dataset_directories=TRAIN_DATASETS,\n",
    "        memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS),\n",
    "        window_size=SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "        time_dim_index=TIME_DIM_INDEX,\n",
    "        source_type=SOURCE_TYPE,\n",
    "        model_type='stae',\n",
    "    )\n",
    "    test_dataset = TemporalAutoencoderDatasetDMD(\n",
    "        dataset_directories=TEST_DATASETS,\n",
    "        memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS),\n",
    "        window_size=SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "        time_dim_index=TIME_DIM_INDEX,\n",
    "        source_type=SOURCE_TYPE,\n",
    "        model_type='stae',\n",
    "    )\n",
    "elif DATASET == 'mrl':\n",
    "    train_val_dataset = STAEDataset(\n",
    "        memory_map_file=NORMAL_MEMORY_MAP,\n",
    "        memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        window_size=SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "    )\n",
    "    test_dataset = STAEDataset(\n",
    "        memory_map_file=ANOMAL_MEMORY_MAP,\n",
    "        memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        window_size=SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "    )\n",
    "\n",
    "# Train validation split\n",
    "train_size = int(TRAIN_SET_RATIO * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_dict['train'],\n",
    "    shuffle=False,  # YOU DON'T WANT TO SHUFFLE TEMPORAL DATA!\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size_dict['valid'],\n",
    "    shuffle=False,\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # batch_size_dict['test'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # int(os.cpu_count()),  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes = axes.flatten()  # type: ignore\n",
    "\n",
    "axes[0].imshow(\n",
    "    test_dataloader.dataset[0]['image'].permute(1, 2, 3, 0)[0],\n",
    "    cmap='gray' if CHANNELS == 1 else None,\n",
    ")\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Mask')\n",
    "\n",
    "axes[1].imshow(\n",
    "    test_dataloader.dataset[0]['mask'].permute(1, 2, 3, 0)[0],\n",
    "    cmap='gray' if CHANNELS == 1 else None,\n",
    ")\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Future Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = STAEModel(\n",
    "    batch_size_dict=batch_size_dict,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lambda_reg=LAMBDA_REG,\n",
    "    use_2d_bottleneck=USE_2D_BOTTLENECK,\n",
    "    regularization=REGULARIZATION,\n",
    "    use_prediction_branch=USE_PREDICTION_BRANCH,\n",
    "    use_extra_3dconv=USE_EXTRA_3DCONV,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input tensor of size (batch_size, channels, time_steps/depth, height, width)\n",
    "INPUT_SAMPLE = torch.randn(\n",
    "    BATCH_SIZE, CHANNELS, SEQUENCE_LENGTH, IMAGE_SIZE, IMAGE_SIZE\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(INPUT_SAMPLE)\n",
    "reconstruction = output[0]\n",
    "prediction = output[1] if USE_PREDICTION_BRANCH else reconstruction\n",
    "\n",
    "assert INPUT_SAMPLE.shape == reconstruction.shape == prediction.shape, (\n",
    "    f'Input and output shapes do not match! Expected: {INPUT_SAMPLE.shape}, got: {output.shape} and {prediction.shape}'\n",
    ")\n",
    "\n",
    "print(summarize_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(LOG_DIR, name=f'{NOW}-{RUN_NAME}', version=VERSION)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=MONITOR,\n",
    "    mode='min',\n",
    "    patience=PATIENCE,\n",
    "    min_delta=MIN_DELTA,\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=EXPERIMENT_DIR,\n",
    "    filename='{epoch}-{valid_total_loss:3f}',\n",
    "    monitor=MONITOR,\n",
    "    save_top_k=1,  # save only the best model\n",
    "    mode='min',\n",
    ")\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',\n",
    "    logger=csv_logger,\n",
    "    callbacks=[model_checkpoint, early_stopping, progress_bar],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    min_epochs=MIN_EPOCHS,\n",
    "    log_every_n_steps=1,  # log every batch\n",
    "    # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "    deterministic=True,\n",
    ")\n",
    "torch.use_deterministic_algorithms(\n",
    "    True, warn_only=True\n",
    ")  # torch 2.5 does not have a deterministic implementation of `max_pool3d_with_indices_backward_cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader,\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Training took {elapsed_time / 60:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Load from MLflow\n",
    "    model_name = f'pytorch-{DRIVER}'\n",
    "    model_version = 7\n",
    "    model_uri = f'models:/{model_name}/{model_version}'\n",
    "    model_ = mlflow.pytorch.load_model(model_uri)\n",
    "else:\n",
    "    model_checkpoint_path = list(EXPERIMENT_DIR.glob('*.ckpt'))[0]\n",
    "    print(f'Loading model from: {model_checkpoint_path}')\n",
    "    model_ = STAEModel.load_from_checkpoint(model_checkpoint_path)\n",
    "model_.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ = L.Trainer(logger=False)  # no need to log anything for validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = trainer_.validate(model_, dataloaders=valid_dataloader, verbose=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "if DATASET == 'mrl':\n",
    "    anomalies = Anomalies.from_file(ANOMALIES_FILE)\n",
    "elif DATASET == 'dmd':\n",
    "    video_lengths = [vid.length for vid in test_dataset.videos]  # type: ignore\n",
    "    # Anomaly files are sorted so that they correspond to the video lengths.\n",
    "    anomalies = Anomalies.from_json(ANOMALIES_FILES, video_lengths)\n",
    "\n",
    "y_true = anomalies.to_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = evaluate_model_parallel(model_, test_dataloader, model_type='stae')\n",
    "test_metrics = {\n",
    "    'mse': sum(errors['mse']) / len(errors['mse']),\n",
    "    'mae': sum(errors['mae']) / len(errors['mae']),\n",
    "    'fro': sum(errors['fro']) / len(errors['fro']),\n",
    "}\n",
    "for metric_name, value in test_metrics.items():\n",
    "    print(f'{metric_name}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = compute_best_roc_auc(y_true, errors)\n",
    "best_metric = str(res_dict['best_metric'])\n",
    "y_proba: list[float] = cast(list[float], res_dict['y_proba'])\n",
    "y_true = y_true[: len(y_proba)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, optimal_threshold = plot_roc_chart(\n",
    "    y_true,\n",
    "    y_proba,\n",
    "    save_path=EXPERIMENT_DIR / ROC_CHART_NAME,\n",
    "    cbar_text=f'Thresholds ({best_metric.upper()})',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_auc, pr_threshold = plot_pr_chart(\n",
    "    y_true,\n",
    "    y_proba,\n",
    "    save_path=EXPERIMENT_DIR / PR_CHART_NAME,\n",
    "    cbar_text=f'Thresholds ({best_metric.upper()})',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_and_anomalies(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_proba,\n",
    "    threshold=optimal_threshold,\n",
    "    save_path=EXPERIMENT_DIR / ERROR_CHART_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temporal_autoencoder_reconstruction(\n",
    "    model_,\n",
    "    test_dataloader,\n",
    "    save_path=EXPERIMENT_DIR / PREDICTIONS_NAME,\n",
    "    time_dim_index=1,\n",
    "    indices=(\n",
    "        [0]  # first video frame\n",
    "        + [anomalies[0].middle()]\n",
    "        + [anomalies[1].middle()]\n",
    "        + [anomalies[2].middle()]\n",
    "        + [anomalies[-2].middle()]\n",
    "        + [anomalies[-1].middle()]\n",
    "    ),\n",
    "    show_heatmap=True,\n",
    "    show_metrics=True,\n",
    "    model_type='stae',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(\n",
    "    EXPERIMENT_DIR / METRICS_CSV_NAME,\n",
    "    save_path=EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME,\n",
    "    metrics={\n",
    "        'fro': 'Frobenius Norm',\n",
    "        'mae': 'Mean Absolute Error',\n",
    "        'reconstruction_loss': 'Reconstruction Loss',  # MSE\n",
    "        'prediction_loss': 'Prediction Loss',\n",
    "        'regularization_loss': 'Regularization Loss',\n",
    "    },\n",
    "    figsize=(38, 6),\n",
    "    loss_name='total_loss',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "predictions = {\n",
    "    'y_true': y_true,\n",
    "    'y_proba': y_proba,\n",
    "    'errors': errors,\n",
    "    'roc_auc': roc_auc,\n",
    "    'best_metric': best_metric,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "}\n",
    "with open(EXPERIMENT_DIR / PREDICTIONS_JSON_NAME, 'w') as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_visualization = torchview.draw_graph(\n",
    "    model_,\n",
    "    input_size=INPUT_SAMPLE.shape,\n",
    "    graph_dir='TB',\n",
    "    depth=3,\n",
    "    roll=True,\n",
    "    expand_nested=True,\n",
    "    graph_name='Temporal Autoencoder',\n",
    "    save_graph=False,\n",
    "    filename=ARCHITECTURE_VISUALIZATION_NAME,\n",
    "    directory=str(EXPERIMENT_DIR),\n",
    ")\n",
    "architecture_visualization.visual_graph.render(format='svg')\n",
    "architecture_visualization.visual_graph.render(format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prediction_branch(model: STAEModel) -> STAEModel:\n",
    "    \"\"\"\n",
    "    Remove the prediction branch from the model. For backward compatibility,\n",
    "    current STAEModel model implementation has a method to remove the prediction branch.\n",
    "    \"\"\"\n",
    "    modified_model = STAEModel(\n",
    "        batch_size_dict=model.batch_size_dict,\n",
    "        learning_rate=model.lr,\n",
    "        lambda_reg=model.lambda_reg,\n",
    "        use_2d_bottleneck=USE_2D_BOTTLENECK,\n",
    "        regularization=model.regularization,  # type: ignore\n",
    "        use_prediction_branch=False,\n",
    "        use_extra_3dconv=USE_EXTRA_3DCONV,\n",
    "    )\n",
    "    modified_model.encoder = copy.deepcopy(model.encoder)\n",
    "    modified_model.decoder = copy.deepcopy(model.decoder)\n",
    "\n",
    "    modified_model.eval()\n",
    "    modified_model.to(model.device)\n",
    "\n",
    "    return modified_model\n",
    "\n",
    "\n",
    "mod_model = remove_prediction_branch(model_)\n",
    "mod_model.to_onnx(\n",
    "    EXPERIMENT_DIR / MODEL_ONNX_NAME,\n",
    "    INPUT_SAMPLE[0].unsqueeze(0),\n",
    "    export_params=True,\n",
    "    dynamo=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    opset_version=20,\n",
    "    do_constant_folding=True,\n",
    "    external_data=False,  # This prevents creating external .data file\n",
    ")\n",
    "\n",
    "onnx_model = onnx.load(EXPERIMENT_DIR / MODEL_ONNX_NAME)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPERIMENT_DIR / MODEL_SUMMARY_NAME, 'w') as f:\n",
    "    f.write(summarize_model(model_))\n",
    "    f.write('\\n')\n",
    "    f.write(model_.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    try:\n",
    "        mlflow.set_tag('Branch', get_current_branch())\n",
    "        mlflow.set_tag('Commit ID', get_commit_id())\n",
    "        mlflow.set_tag('Dataset', DATASET_NAME)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    mlflow.log_metric('roc_auc', roc_auc)\n",
    "    mlflow.log_metric('pr_auc', pr_auc)\n",
    "    mlflow.log_metric('pr_threshold', pr_threshold)\n",
    "    mlflow.log_metric('optimal_threshold', optimal_threshold)\n",
    "    log_dict_to_mlflow(valid_metrics, 'metric')\n",
    "    log_dict_to_mlflow(test_metrics, 'metric')\n",
    "    log_dict_to_mlflow(get_submodule_param_count(model_), 'param')\n",
    "\n",
    "    mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "    mlflow.log_param('max_epochs', MAX_EPOCHS)\n",
    "    mlflow.log_param('min_epochs', MIN_EPOCHS)\n",
    "    mlflow.log_param('min_delta', MIN_DELTA)\n",
    "    mlflow.log_param('early_stopping', get_early_stopping_epoch(EXPERIMENT_DIR))\n",
    "    mlflow.log_param('monitor', MONITOR)\n",
    "    mlflow.log_param('patience', PATIENCE)\n",
    "    mlflow.log_param('image_size', IMAGE_SIZE)\n",
    "    mlflow.log_param('learning_rate', LEARNING_RATE)\n",
    "    mlflow.log_param('lambda_regularization', LAMBDA_REG)\n",
    "    mlflow.log_param('seed', SEED)\n",
    "    mlflow.log_param('sequence_length', SEQUENCE_LENGTH)\n",
    "    mlflow.log_param('time_step', TIME_STEP)\n",
    "    mlflow.log_param('train_set_ratio', TRAIN_SET_RATIO)\n",
    "    mlflow.log_param('train_sequences', len(train_dataset))\n",
    "    mlflow.log_param('driver', DRIVER)\n",
    "    mlflow.log_param('best_metric', best_metric)\n",
    "    mlflow.log_param('use_mask', USE_MASK)\n",
    "    mlflow.log_param('training_time_s', elapsed_time)\n",
    "    mlflow.log_param('training_time_m', round(elapsed_time / 60))\n",
    "    mlflow.log_param('use_2d_bottleneck', USE_2D_BOTTLENECK)\n",
    "    mlflow.log_param('use_extra_3dconv', USE_EXTRA_3DCONV)\n",
    "    mlflow.log_param('regularization', REGULARIZATION)\n",
    "    mlflow.log_param('use_prediction_branch', USE_PREDICTION_BRANCH)\n",
    "    mlflow.log_param('source_type', SOURCE_TYPE)\n",
    "    if DATASET == 'dmd':\n",
    "        mlflow.log_param('train_sessions', TRAIN_SESSIONS)\n",
    "        mlflow.log_param('test_sessions', TEST_SESSIONS)\n",
    "\n",
    "    # CSV metrics, learning curves, predictions, notebook\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / METRICS_CSV_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME), MLFLOW_ARTIFACT_DIR\n",
    "    )\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / PREDICTIONS_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / ROC_CHART_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / MODEL_SUMMARY_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(str(Path().cwd() / NOTEBOOK_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / ERROR_CHART_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / PR_CHART_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / PREDICTIONS_JSON_NAME), MLFLOW_ARTIFACT_DIR\n",
    "    )\n",
    "\n",
    "    # Network visualization with `torchview`\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / (ARCHITECTURE_VISUALIZATION_NAME + '.svg')),\n",
    "        MLFLOW_ARTIFACT_DIR,\n",
    "    )\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / (ARCHITECTURE_VISUALIZATION_NAME + '.png')),\n",
    "        MLFLOW_ARTIFACT_DIR,\n",
    "    )\n",
    "\n",
    "    # Log parameters for inference in the model artifact directory\n",
    "    # for later use during inference.\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        file_path = Path(temp_dir) / 'inference.json'\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(\n",
    "                {\n",
    "                    'roc_threshold': optimal_threshold,\n",
    "                    'pr_threshold': pr_threshold,\n",
    "                    'max_error': max(errors[best_metric]),\n",
    "                    'min_error': min(errors[best_metric]),\n",
    "                    'best_metric': best_metric,\n",
    "                },\n",
    "                f,\n",
    "            )\n",
    "        mlflow.log_artifact(str(file_path), artifact_path='model')\n",
    "\n",
    "    # Models are versioned by default\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model_,\n",
    "        artifact_path='model',\n",
    "        registered_model_name=f'pytorch-{DRIVER}',\n",
    "        signature=infer_signature(\n",
    "            INPUT_SAMPLE.numpy(), INPUT_SAMPLE.numpy(), dict(training=False)\n",
    "        ),\n",
    "    )\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / MODEL_ONNX_NAME), 'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
