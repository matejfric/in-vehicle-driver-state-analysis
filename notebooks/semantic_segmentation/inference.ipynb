{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Inference\n",
    "\n",
    "Outputs segmentation overlay video for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = str(Path.cwd().parent.parent)\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sam2util import convert_images_to_mp4\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.inference import (\n",
    "    filter_small_segments,\n",
    "    init_dagshub,\n",
    "    load_image,\n",
    "    load_model_from_dagshub,\n",
    "    measure_model_fps,\n",
    "    predict,\n",
    ")\n",
    "from model.plot import plot_single_prediction  # noqa: F401\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now() -> str:\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_name = 'pytorch-2024-10-28-094601-unet-efficientnet-b0'\n",
    "model_version = 1\n",
    "input_dir = (\n",
    "    Path().home() / 'source/driver-dataset/images/2022_09_14_stribny_enyaq/normal'\n",
    ")\n",
    "output_dir = f'outputs/{now()}-{model_name}-v{model_version}'\n",
    "fps = 30\n",
    "interpolation_shape: tuple[int, int] | None = (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = Path(input_dir)\n",
    "OUTPUT_DIR = Path(output_dir) if output_dir else INPUT_DIR.parent / 'masks'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "FPS = fps if isinstance(fps, int) else 30\n",
    "INTERPOLATION_SHAPE = interpolation_shape if interpolation_shape else (256, 256)\n",
    "\n",
    "assert INPUT_DIR.exists(), f'Input directory `{INPUT_DIR}` does not exist.'\n",
    "assert len(INTERPOLATION_SHAPE) == 2 and all(\n",
    "    [isinstance(x, int) for x in INTERPOLATION_SHAPE]\n",
    "), 'Interpolation shape must be a tuple of two integers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dagshub(repo_name='driver-state')\n",
    "model = load_model_from_dagshub(model_name, model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in tqdm(sorted(INPUT_DIR.glob('*.jpg'))):\n",
    "    image = load_image(image_path)\n",
    "    mask = predict(model, image, input_size=256, output_size=INTERPOLATION_SHAPE)\n",
    "    # plot_single_prediction(image, mask)\n",
    "\n",
    "    mask = mask.squeeze().numpy()\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Filter out small segments\n",
    "    filtered_binary_mask = filter_small_segments(\n",
    "        binary_mask, min_area=(INTERPOLATION_SHAPE[0] // 4) ** 2\n",
    "    )\n",
    "\n",
    "    mask_rgba = np.zeros((*mask.shape, 4), dtype=np.uint8)\n",
    "    mask_rgba[..., 0] = 255  # Red\n",
    "    mask_rgba[..., 3] = filtered_binary_mask * 102  # Alpha channel with transparency\n",
    "    mask_img = Image.fromarray(mask_rgba, 'RGBA')\n",
    "    image_rgba = image.resize((mask.shape[0], mask.shape[1])).convert('RGBA')\n",
    "    overlay_img = Image.alpha_composite(image_rgba, mask_img)\n",
    "    overlay_img.convert('RGB').save(\n",
    "        OUTPUT_DIR / f'{int(image_path.stem) // 30:05d}.jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR / 'readme.txt', 'w') as f:\n",
    "    f.write(f'Timestamp: {datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")}\\n')\n",
    "    f.write(f'Input path: {INPUT_DIR}\\n')\n",
    "    f.write(f'Model: {model_name} v{model_version}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_model_fps(model, INPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR.parent.name, INPUT_DIR.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_name = f'{INPUT_DIR.parent.name}_{INPUT_DIR.name}_{FPS}fps.mp4'\n",
    "convert_images_to_mp4(OUTPUT_DIR, OUTPUT_DIR / output_video_name, fps=FPS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
