{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver State Analysis\n",
    "\n",
    "[https://dagshub.com/matejfric/driver-state](https://dagshub.com/matejfric/driver-state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "repo_root = str(Path.cwd().parent.parent)\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "import albumentations as albu\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import onnx\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Pytorch Lightning EarlyStopping callback does not recover the best weights as in Keras!\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# https://github.com/Lightning-AI/pytorch-lightning/discussions/10399,\n",
    "# https://pytorch-lightning.readthedocs.io/en/1.5.10/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from model import (\n",
    "    BatchSizeDict,\n",
    "    DatasetPathsLoader,\n",
    "    DatasetSplit,\n",
    "    SegmentationModel,\n",
    ")\n",
    "from model.augmentation import (\n",
    "    compose_transforms,\n",
    "    hard_transforms,\n",
    "    post_transforms,\n",
    "    pre_transforms,\n",
    ")\n",
    "from model.git import get_commit_id, get_current_branch\n",
    "from model.plot import (\n",
    "    plot_learning_curves,\n",
    "    plot_predictions_compact,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Experiment logging\n",
    "REPO_NAME = 'driver-seg'\n",
    "USER_NAME = 'matejfric'\n",
    "dagshub.init(REPO_NAME, USER_NAME, mlflow=True)  # type: ignore\n",
    "\n",
    "# Reproducibility\n",
    "# https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "SEED = 42\n",
    "L.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(\n",
    "    f'torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, lightning: {L.__version__}'  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model            | Channel Multiplier | Depth Multiplier | Resolution | Dropout Rate |\n",
    "|-----------------|------------------|----------------|------------|--------------|\n",
    "| efficientnet-b0 | 1.0              | 1.0            | 224        | 0.2          |\n",
    "| efficientnet-b1 | 1.0              | 1.1            | 240        | 0.2          |\n",
    "| efficientnet-b2 | 1.1              | 1.2            | 260        | 0.3          |\n",
    "| efficientnet-b3 | 1.2              | 1.4            | 300        | 0.3          |\n",
    "| efficientnet-b4 | 1.4              | 1.8            | 380        | 0.4          |\n",
    "| efficientnet-b5 | 1.6              | 2.2            | 456        | 0.4          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# ----------------------------------------\n",
    "ENCODER = 'efficientnet-b0'  # 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'efficientnet-b1', 'mit_b1', ...\n",
    "DECODER = 'unet'  # 'unet', 'unetplusplus', 'deeplabv3', 'deeplabv3plus', 'fpn', ...  # 'unet', 'unetplusplus', 'deeplabv3', 'deeplabv3plus', 'fpn', ...\n",
    "FREEZE_ENCODER = True\n",
    "MAX_EPOCHS = 10\n",
    "MONITOR = 'valid_loss'\n",
    "PATIENCE = 10\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "LEARNING_RATE = 1e-4\n",
    "AUGMENTATION = True\n",
    "\n",
    "# LOGGING\n",
    "# ----------------------------------------\n",
    "LOG_DIR = Path('logs')\n",
    "EXPERIMENT_NAME = f'{datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")}-{DECODER}-{ENCODER}-test-new-dataset'\n",
    "VERSION = 0\n",
    "EXPERIMENT_DIR = LOG_DIR / EXPERIMENT_NAME / f'version_{VERSION}'\n",
    "DATASET_NAME = (\n",
    "    '2025-02-26-driver-segmentation-dataset'  # '2024-09-15-driver-segmentation-dataset'\n",
    ")\n",
    "\n",
    "MLFLOW_ARTIFACT_DIR = 'outputs'\n",
    "METRICS_CSV_NAME = 'metrics.csv'\n",
    "LEARNING_CURVES_PDF_NAME = 'learning_curves.pdf'\n",
    "PREDICTIONS_PNG_NAME = 'predictions.png'\n",
    "TRAIN_TRANSFORMS_JSON_NAME = 'train_transforms.json'\n",
    "MODEL_ONNX_NAME = 'model.onnx'\n",
    "\n",
    "# DATASET\n",
    "# ----------------------------------------\n",
    "DATASET_DIR = Path.home() / f'source/driver-dataset/{DATASET_NAME}'\n",
    "assert DATASET_DIR.exists(), f'Dataset directory does not exist: {DATASET_DIR}'\n",
    "\n",
    "TRAIN_SET_DIR = 'train'\n",
    "VALID_SET_DIR = 'validation'\n",
    "TEST_SET_DIR = 'test'\n",
    "\n",
    "IMAGES_DIR = 'images'\n",
    "MASKS_DIR = 'masks'\n",
    "\n",
    "TRAIN_IMAGES = sorted((DATASET_DIR / TRAIN_SET_DIR / IMAGES_DIR).glob('*.jpg'))\n",
    "TRAIN_MASKS = sorted((DATASET_DIR / TRAIN_SET_DIR / MASKS_DIR).glob('*.png'))\n",
    "\n",
    "VALID_IMAGES = sorted((DATASET_DIR / VALID_SET_DIR / IMAGES_DIR).glob('*.jpg'))\n",
    "VALID_MASKS = sorted((DATASET_DIR / VALID_SET_DIR / MASKS_DIR).glob('*.png'))\n",
    "\n",
    "TEST_IMAGES = sorted((DATASET_DIR / TEST_SET_DIR / IMAGES_DIR).glob('*.jpg'))\n",
    "TEST_MASKS = sorted((DATASET_DIR / TEST_SET_DIR / MASKS_DIR).glob('*.png'))\n",
    "\n",
    "print(\n",
    "    f' Train: {len(TRAIN_IMAGES)} images, {len(TRAIN_MASKS)} masks\\n',\n",
    "    f'Valid: {len(VALID_IMAGES)} images, {len(VALID_MASKS)} masks\\n',\n",
    "    f'Test: {len(TEST_IMAGES)} images, {len(TEST_MASKS)} masks',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_names = list(np.unique(['_'.join(im.name.split('_')[:-1]) for im in TRAIN_IMAGES]))\n",
    "pprint(im_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude images from the training set\n",
    "# TRAIN_IMAGES = [img for img in TRAIN_IMAGES if 'stribny' not in img.stem]\n",
    "# TRAIN_MASKS = [mask for mask in TRAIN_MASKS if 'stribny' not in mask.stem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUGMENTATION:\n",
    "    train_transforms = compose_transforms(\n",
    "        [\n",
    "            pre_transforms(image_size=IMAGE_SIZE),\n",
    "            hard_transforms(),\n",
    "            post_transforms(),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    train_transforms = compose_transforms(\n",
    "        [\n",
    "            pre_transforms(image_size=IMAGE_SIZE),\n",
    "            post_transforms(),\n",
    "        ]\n",
    "    )\n",
    "valid_transforms = compose_transforms(\n",
    "    [\n",
    "        pre_transforms(image_size=IMAGE_SIZE),\n",
    "        post_transforms(),\n",
    "    ]\n",
    ")\n",
    "test_transforms = compose_transforms(\n",
    "    [\n",
    "        pre_transforms(image_size=IMAGE_SIZE),\n",
    "        post_transforms(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = DatasetPathsLoader(\n",
    "    train=DatasetSplit(images=TRAIN_IMAGES, masks=TRAIN_MASKS),\n",
    "    valid=DatasetSplit(images=VALID_IMAGES, masks=VALID_MASKS),\n",
    "    test=DatasetSplit(images=TEST_IMAGES, masks=TEST_MASKS),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_DICT = BatchSizeDict(\n",
    "    {'train': BATCH_SIZE, 'valid': BATCH_SIZE, 'test': BATCH_SIZE}\n",
    ")\n",
    "loaders = dataset_loader.get_loaders(\n",
    "    # set to zero if RuntimeError: Trying to resize storage that is not resizable\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    "    batch_size_dict=BATCH_SIZE_DICT,\n",
    "    train_transforms=train_transforms,\n",
    "    valid_transforms=valid_transforms,\n",
    "    test_transforms=test_transforms,\n",
    ")\n",
    "\n",
    "train_dataloader = loaders['train']\n",
    "valid_dataloader = loaders['valid']\n",
    "test_dataloader = loaders['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegmentationModel(\n",
    "    DECODER,\n",
    "    ENCODER,\n",
    "    in_channels=3,\n",
    "    out_classes=1,\n",
    "    batch_size_dict=BATCH_SIZE_DICT,\n",
    "    freeze_encoder=FREEZE_ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(LOG_DIR, name=EXPERIMENT_NAME, version=VERSION)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=MONITOR,\n",
    "    mode='min',\n",
    "    patience=PATIENCE,\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=EXPERIMENT_DIR,\n",
    "    filename='{epoch}-{valid_loss:3f}',\n",
    "    monitor=MONITOR,\n",
    "    save_top_k=1,  # save only the best model\n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    logger=csv_logger,\n",
    "    callbacks=[model_checkpoint, early_stopping],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    log_every_n_steps=1,  # log every batch\n",
    "    # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from MLflow\n",
    "# model_name = 'pytorch-unet-resnet18'\n",
    "# model_version = 2\n",
    "# model_uri = f'models:/{model_name}/{model_version}'\n",
    "# model_ = mlflow.pytorch.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = list(EXPERIMENT_DIR.glob('*.ckpt'))[0]\n",
    "model_ = SegmentationModel.load_from_checkpoint(model_checkpoint_path)\n",
    "trainer_ = L.Trainer(logger=False)  # no need to log anything for validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = trainer_.validate(model_, dataloaders=valid_dataloader, verbose=False)[\n",
    "    0\n",
    "]\n",
    "pprint(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer_.test(model_, dataloaders=test_dataloader, verbose=False)[0]\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_compact(\n",
    "    model_,\n",
    "    test_dataloader,\n",
    "    save_path=EXPERIMENT_DIR / PREDICTIONS_PNG_NAME,\n",
    "    n_cols=4,\n",
    "    limit=12,\n",
    "    seed=SEED,\n",
    "    cmap='jet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(\n",
    "    EXPERIMENT_DIR / METRICS_CSV_NAME,\n",
    "    save_path=EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME,\n",
    "    metrics={'jaccard_index': 'Jaccard Index', 'f1_score': 'F1 Score'},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SAMPLE = torch.randn((1, 3, 256, 256), dtype=torch.float32)\n",
    "OUTPUT_SAMPLE = torch.randn((1, 1, 256, 256), dtype=torch.float32)\n",
    "model_.to_onnx(\n",
    "    EXPERIMENT_DIR / MODEL_ONNX_NAME, INPUT_SAMPLE, export_params=True, dynamo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(EXPERIMENT_DIR / MODEL_ONNX_NAME)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transforms for experiment logging\n",
    "albu.save(train_transforms, EXPERIMENT_DIR / TRAIN_TRANSFORMS_JSON_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_stopping_epoch() -> int | None:\n",
    "    checkpoint = list(EXPERIMENT_DIR.glob('*.ckpt'))[0].stem\n",
    "    pattern = r'epoch=(\\d+)'\n",
    "    match = re.search(pattern, checkpoint)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dict_to_mlflow(dictionary: dict[str, float]) -> None:\n",
    "    for k, v in dictionary.items():\n",
    "        mlflow.log_metric(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f'{EXPERIMENT_NAME}') as run:\n",
    "    mlflow.set_tag('Dataset', DATASET_NAME)\n",
    "    try:\n",
    "        mlflow.set_tag('Branch', get_current_branch())\n",
    "        mlflow.set_tag('Commit ID', get_commit_id())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    log_dict_to_mlflow(dict(valid_metrics))\n",
    "    log_dict_to_mlflow(dict(test_metrics))\n",
    "\n",
    "    mlflow.log_param('encoder', ENCODER)\n",
    "    mlflow.log_param('decoder', DECODER)\n",
    "    mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "    mlflow.log_param('max_epochs', MAX_EPOCHS)\n",
    "    mlflow.log_param('early_stopping', get_early_stopping_epoch())\n",
    "    mlflow.log_param('monitor', MONITOR)\n",
    "    mlflow.log_param('patience', PATIENCE)\n",
    "    mlflow.log_param('image_size', IMAGE_SIZE)\n",
    "    mlflow.log_param('frozen_encoder', FREEZE_ENCODER)\n",
    "    mlflow.log_param('encoder_weights', ENCODER_WEIGHTS)\n",
    "    mlflow.log_param('learning_rate', LEARNING_RATE)\n",
    "    mlflow.log_param('augmentation', AUGMENTATION)\n",
    "\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / METRICS_CSV_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME), MLFLOW_ARTIFACT_DIR\n",
    "    )\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / PREDICTIONS_PNG_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / TRAIN_TRANSFORMS_JSON_NAME), MLFLOW_ARTIFACT_DIR\n",
    "    )\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / MODEL_ONNX_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact('train_segmentation.ipynb', MLFLOW_ARTIFACT_DIR)\n",
    "\n",
    "    # Models are versioned by default\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model_,\n",
    "        artifact_path='model',\n",
    "        registered_model_name=f'pytorch-{EXPERIMENT_NAME}',\n",
    "        signature=infer_signature(\n",
    "            INPUT_SAMPLE.numpy(), OUTPUT_SAMPLE.numpy(), dict(training=False)\n",
    "        ),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
