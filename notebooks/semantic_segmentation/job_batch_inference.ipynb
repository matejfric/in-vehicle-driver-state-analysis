{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Batch Inference With Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from collections.abc import Generator\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from os import cpu_count\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from PIL import Image\n",
    "from sam2util import convert_images_to_mp4\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.common import (\n",
    "    create_video_from_images,\n",
    "    crop_driver_image_contains,\n",
    "    pad_to_square,\n",
    ")\n",
    "from model.inference import (\n",
    "    filter_small_segments,\n",
    "    init_dagshub,\n",
    "    load_model_from_dagshub,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_name = 'pytorch-sem-seg'\n",
    "model_version = 26\n",
    "input_dir = (\n",
    "    Path().home() / 'source/driver-dataset/dmd/gA_1_s1_2019-03-08T09;31;15+01;00/'\n",
    ")\n",
    "batch_size = 16\n",
    "repo_name = 'driver-seg'\n",
    "dataset = 'dmd'\n",
    "source_type = 'ir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET: Literal['mrl', 'dmd'] = dataset or 'mrl'\n",
    "INPUT_DIR = Path(input_dir)\n",
    "SOURCE_TYPE = source_type or 'rgb'\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = batch_size if isinstance(batch_size, int) else 16\n",
    "\n",
    "assert INPUT_DIR.exists(), f'Input directory `{INPUT_DIR}` does not exist.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ext = 'jpg' if SOURCE_TYPE == 'rgb' else 'png'\n",
    "\n",
    "if DATASET == 'mrl':\n",
    "    image_paths = sorted(INPUT_DIR.glob(f'*.{img_ext}'))\n",
    "    OUTPUT_DIR = INPUT_DIR.parent / 'masks'\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "elif DATASET == 'dmd':\n",
    "    clip_dirs = [d for d in INPUT_DIR.rglob(SOURCE_TYPE) if d.is_dir()]\n",
    "    image_paths = sorted(\n",
    "        [i for d in clip_dirs for i in d.glob(f'*.{img_ext}')], key=lambda x: x.stem\n",
    "    )\n",
    "    OUTPUT_DIR = INPUT_DIR\n",
    "else:\n",
    "    raise ValueError(f'Unknown dataset `{DATASET}`. Supported: `mrl`, `dmd`.')\n",
    "\n",
    "assert len(image_paths) > 0, f'No images found in `{INPUT_DIR}`.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dagshub(repo_name=repo_name)\n",
    "model_ = load_model_from_dagshub(model_name, model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_image(\n",
    "    image_path: Path, resize: tuple[int, int], transforms: Any\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Helper function to load and process a single image.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    if DATASET == 'mrl':\n",
    "        processed_image = crop_driver_image_contains(image, image_path).resize(\n",
    "            resize, resample=Image.Resampling.NEAREST\n",
    "        )\n",
    "    elif DATASET == 'dmd':\n",
    "        processed_image = pad_to_square(image).resize(\n",
    "            resize, resample=Image.Resampling.NEAREST\n",
    "        )\n",
    "\n",
    "    return transforms(image=np.asanyarray(processed_image))['image']\n",
    "\n",
    "\n",
    "def data_loader(\n",
    "    image_paths: list[Path],\n",
    "    batch_size: int = 32,\n",
    "    resize: tuple[int, int] = (256, 256),\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    ") -> Generator[tuple[torch.Tensor, list[Path]]]:\n",
    "    transforms = ToTensorV2()\n",
    "\n",
    "    def func(path: Path) -> torch.Tensor:\n",
    "        return load_and_process_image(path, resize, transforms)\n",
    "\n",
    "    n_workers = cpu_count() or 1\n",
    "    n_workers = 8 if n_workers >= 8 else n_workers\n",
    "\n",
    "    with ThreadPoolExecutor(n_workers) as executor:\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            image_paths_batch = image_paths[i : i + batch_size]\n",
    "            images = list(\n",
    "                executor.map(\n",
    "                    func,\n",
    "                    image_paths_batch,\n",
    "                )\n",
    "            )\n",
    "            tensor = torch.stack(images).to(device)\n",
    "            if SOURCE_TYPE == 'ir':\n",
    "                tensor = tensor.repeat(1, 3, 1, 1)\n",
    "            yield tensor, image_paths_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_mask(mask: torch.Tensor, image_path: Path) -> None:\n",
    "    mask_numpy = mask.squeeze().numpy()\n",
    "    binary_mask = (mask_numpy > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Filter out small segments\n",
    "    filtered_binary_mask = filter_small_segments(binary_mask, min_area=64**2)\n",
    "\n",
    "    if DATASET == 'mrl':\n",
    "        output_file_path = OUTPUT_DIR / f'{image_path.stem}.png'\n",
    "    elif DATASET == 'dmd':\n",
    "        dir = image_path.parent.parent / 'masks_ir'\n",
    "        dir.mkdir(exist_ok=True)\n",
    "        output_file_path = dir / f'{image_path.stem}.png'\n",
    "\n",
    "    cv2.imwrite(str(output_file_path), filtered_binary_mask * 255)\n",
    "    assert output_file_path.exists(), f'Failed to save mask to `{output_file_path}`.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the device (GPU/CPU)\n",
    "model_ = model_.to(device)\n",
    "loader = data_loader(image_paths, BATCH_SIZE, (IMAGE_SIZE, IMAGE_SIZE), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = ThreadPoolExecutor(4)\n",
    "for images, image_paths_ in tqdm(loader, total=len(image_paths) // BATCH_SIZE):\n",
    "    with torch.no_grad():\n",
    "        prediction = model_(images)\n",
    "        masks = prediction.sigmoid()\n",
    "\n",
    "    for mask, image_path in zip(masks, image_paths_):\n",
    "        executor.submit(process_and_save_mask, mask.to('cpu'), image_path)\n",
    "\n",
    "executor.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR / 'readme.txt', 'w') as f:\n",
    "    f.write(f'Timestamp: {datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")}\\n')\n",
    "    f.write(f'Input path: {INPUT_DIR}\\n')\n",
    "    f.write(f'Model: {model_name} v{model_version}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'mrl':\n",
    "    convert_images_to_mp4(\n",
    "        OUTPUT_DIR, OUTPUT_DIR / 'masks.mp4', fps=30, image_format='png'\n",
    "    )\n",
    "else:\n",
    "    create_video_from_images(\n",
    "        output_path=OUTPUT_DIR / 'masks_ir.mp4',\n",
    "        frame_paths=[p.parent.parent / 'masks_ir' / p.name for p in image_paths],\n",
    "        fps=30,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
