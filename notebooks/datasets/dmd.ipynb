{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMD\n",
    "\n",
    "Various preprocessing functions for the DMD (dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor  # noqa F401\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import cv2  # noqa F401\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.common import (\n",
    "    create_video_from_images,  # noqa F401\n",
    "    crop_aspect_ratio,  # noqa F401\n",
    ")\n",
    "from model.depth import convert_video_to_depth  # noqa F401\n",
    "from model.dmd import (\n",
    "    CATEGORIES,\n",
    "    DRIVER_SESSION_MAPPING,  # noqa F401\n",
    "    ROOT,\n",
    "    convert_depth_images_to_video,  # noqa F401\n",
    "    convert_frames_to_video,  # noqa F401\n",
    "    extract_frames,\n",
    "    get_all_sessions,\n",
    "    get_clips,  # noqa F401\n",
    ")\n",
    "\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Frames from Video\n",
    "\n",
    "Distribute video frames between distractions and \"normal\" activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = get_all_sessions()\n",
    "for session in tqdm(sessions):\n",
    "    for source_type in ['rgb', 'depth', 'ir']:\n",
    "        source_video_extension: Literal['mp4', 'avi'] = (\n",
    "            'avi' if source_type == 'depth' else 'mp4'\n",
    "        )\n",
    "        input_video_path = (\n",
    "            ROOT / session / f'{session}_{source_type}_body.{source_video_extension}'\n",
    "        )\n",
    "        annotations_file_path = ROOT / session / f'{session}.json'\n",
    "\n",
    "        assert input_video_path.exists(), f'File not found: {input_video_path}'\n",
    "        assert annotations_file_path.exists(), (\n",
    "            f'File not found: {annotations_file_path}'\n",
    "        )\n",
    "        print(f'Input video path: {input_video_path}')\n",
    "        print(f'Annotations file path: {annotations_file_path}')\n",
    "\n",
    "        extract_frames(\n",
    "            input_video_path=input_video_path,\n",
    "            annotations_file_path=annotations_file_path,\n",
    "            force_overwrite=True,\n",
    "            source_type=source_type,\n",
    "            skip_output_directory_setup=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Depth Anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_frames_to_video(session, source_type=source_type, preset='slow', crf=10)\n",
    "# convert_video_to_depth(ROOT / session, source_type='crop_rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert depth images to video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_depth_images_to_video(\n",
    "#     session, 'normal', 1, extension='png', fps=30, directory='source_depth'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Clip Masks to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = ROOT / 'gA_4_s1_2019-03-13T10;36;15+01;00'\n",
    "# assert session.exists(), f'Path not found: {session}'\n",
    "\n",
    "# sequences = get_clips(session, 'anomal') + get_clips(session, 'normal')\n",
    "# frame_paths = sorted(\n",
    "#     [img for x in sequences for img in (x / 'masks').glob('*.png')],\n",
    "#     key=lambda x: int(x.stem),\n",
    "# )\n",
    "\n",
    "# create_video_from_images(\n",
    "#     frame_paths,\n",
    "#     session / f'{session.name}_masks.mp4',\n",
    "#     fps=30,\n",
    "#     size=(256, 256),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Existing Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dirs: list[Path] = [x for x in ROOT.glob('*') if x.is_dir()]\n",
    "session_subdirs: list[Path] = [\n",
    "    ses_dir / class_dir for ses_dir in session_dirs for class_dir in CATEGORIES\n",
    "]\n",
    "all_subdirs: list[list[Path]] = [\n",
    "    list(subdir.glob('*')) for subdir in session_subdirs if subdir.is_dir()\n",
    "]\n",
    "all_dirs = sorted(\n",
    "    [\n",
    "        dir\n",
    "        for subdirs in all_subdirs\n",
    "        for dir in subdirs\n",
    "        if (dir / 'rgb').is_dir() and len(list((dir / 'rgb').glob('*.jpg'))) > 0\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir in tqdm(all_dirs):\n",
    "#     old = dir / 'source_depth'\n",
    "#     new = dir / 'source_depth_original'\n",
    "\n",
    "#     if old.exists() and old.is_dir():\n",
    "#         old.rename(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove first N images (e.g., depth camera warmup)\n",
    "# for dir in tqdm(all_dirs):\n",
    "#     images = sorted((dir / 'source_depth').glob('*.png'), key=lambda x: int(x.stem))\n",
    "#     for img_path in images:\n",
    "#         if int(img_path.stem) < 30:\n",
    "#             img_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_image(img_path: Path, output_dir: Path) -> None:\n",
    "#     # Read and process the image\n",
    "#     img = cv2.imread(str(img_path))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img = crop_aspect_ratio(img, 3 / 4)  # from square to 3:4\n",
    "#     img = crop_aspect_ratio(img, 4 / 3)  # from 3:4 to 4:3\n",
    "#     img = cv2.resize(img, (480, 360), interpolation=cv2.INTER_AREA)\n",
    "#     cv2.imwrite(str(output_dir / img_path.name), img)\n",
    "\n",
    "\n",
    "# def process_directory(dir: Path) -> None:\n",
    "#     sensor_images = sorted(\n",
    "#         (dir / 'source_depth_original').glob('*.png'),\n",
    "#         key=lambda x: int(x.stem),\n",
    "#     )\n",
    "#     output_dir = dir / 'source_depth'\n",
    "#     output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "#     with ProcessPoolExecutor() as executor:\n",
    "#         for img_path in sensor_images:\n",
    "#             executor.submit(process_image, img_path, output_dir)\n",
    "\n",
    "\n",
    "# for dir in tqdm(all_dirs):\n",
    "#     process_directory(dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
