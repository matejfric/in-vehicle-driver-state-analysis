{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver State Anomaly Detection With Temporal Autoencoders\n",
    "\n",
    "[https://dagshub.com/matejfric/driver-state](https://dagshub.com/matejfric/driver-state)\n",
    "\n",
    "TODO: setup a pre-commit hook for https://github.com/mwouts/jupytext and Ruff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Literal\n",
    "\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "# Pytorch Lightning EarlyStopping callback does not recover the best weights as in Keras!\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# https://github.com/Lightning-AI/pytorch-lightning/discussions/10399,\n",
    "# https://pytorch-lightning.readthedocs.io/en/1.5.10/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from model import (\n",
    "    AutoencoderModel,\n",
    ")\n",
    "from model.ae import (\n",
    "    LSTMDecoder,\n",
    "    LSTMEncoder,\n",
    "    TemporalAutoencoderModel,\n",
    "    summarize_model,\n",
    ")\n",
    "from model.common import Anomalies, BatchSizeDict\n",
    "from model.dataset import TemporalAutoencoderDataset\n",
    "from model.git import get_commit_id, get_current_branch\n",
    "from model.plot import (\n",
    "    plot_learning_curves,\n",
    "    show_examples,  # noqa F401 TODO\n",
    "    show_random,  # noqa F401 TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Experiment logging\n",
    "REPO_NAME = 'driver-state'\n",
    "USER_NAME = 'matejfric'\n",
    "dagshub.init(REPO_NAME, USER_NAME, mlflow=True)  # type: ignore\n",
    "\n",
    "# Reproducibility\n",
    "# https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "SEED = 42\n",
    "L.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(\n",
    "    f'torch: {torch.__version__}, cuda: {torch.cuda.is_available()}, lightning: {L.__version__}'  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# ----------------------------------------\n",
    "MAX_EPOCHS = 10\n",
    "MONITOR = 'valid_loss'\n",
    "PATIENCE = 2\n",
    "IMAGE_SIZE = 256  # 224\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "LOSS_FUNCTION = 'mse'  # 'mae'\n",
    "TRAIN_NOISE_STD_INPUT = 0.0  # 0.025\n",
    "TRAIN_NOISE_STD_LATENT = 0.0  # 0.025\n",
    "TIME_STEPS = 4\n",
    "TRAIN_SET_RATIO = 0.9\n",
    "\n",
    "# LOGGING\n",
    "# ----------------------------------------\n",
    "LOG_DIR = Path('logs')\n",
    "EXPERIMENT_NAME = f'{datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")}-tae'\n",
    "VERSION = 0\n",
    "EXPERIMENT_DIR = LOG_DIR / EXPERIMENT_NAME / f'version_{VERSION}'\n",
    "DATASET_NAME = '2024-10-28-driver-all-frames/2021_08_31_geordi_enyaq'\n",
    "\n",
    "MLFLOW_ARTIFACT_DIR = 'outputs'\n",
    "METRICS_CSV_NAME = 'metrics.csv'\n",
    "LEARNING_CURVES_PDF_NAME = 'learning_curves.pdf'\n",
    "PREDICTIONS_PNG_NAME = 'predictions.png'\n",
    "TRAIN_TRANSFORMS_JSON_NAME = 'train_transforms.json'\n",
    "NOTEBOOK_NAME = 'anomaly_detection.ipynb'\n",
    "\n",
    "# DATASET\n",
    "# ----------------------------------------\n",
    "DATASET_DIR = Path().home() / f'source/driver-dataset/{DATASET_NAME}'\n",
    "\n",
    "NORMAL_MEMORY_MAP = DATASET_DIR / 'normal' / 'memory_maps' / 'depth_256.dat'\n",
    "ANOMAL_MEMORY_MAP = DATASET_DIR / 'anomal' / 'memory_maps' / 'depth_256.dat'\n",
    "ANOMALIES_FILE = DATASET_DIR / 'anomal' / 'labels.txt'\n",
    "\n",
    "assert (\n",
    "    NORMAL_MEMORY_MAP.exists()\n",
    "), f'Normal memory map does not exist: {NORMAL_MEMORY_MAP}'\n",
    "assert (\n",
    "    ANOMAL_MEMORY_MAP.exists()\n",
    "), f'Anomal memory map does not exist: {ANOMAL_MEMORY_MAP}'\n",
    "assert ANOMALIES_FILE.exists(), f'Anomalies file does not exist: {ANOMALIES_FILE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple test case for forward pass\n",
    "# ---------------------------------\n",
    "\n",
    "encoder = LSTMEncoder(n_time_steps=TIME_STEPS)\n",
    "decoder = LSTMDecoder(n_time_steps=TIME_STEPS, n_image_channels=1)\n",
    "\n",
    "# Test input tensor of size (batch_size, time_steps, channels, height, width)\n",
    "x = torch.randn(BATCH_SIZE, TIME_STEPS, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "# Forward pass through the encoder and decoder\n",
    "encoded = encoder(x)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "# Check the shapes\n",
    "print(f'Input shape: {x.shape}')\n",
    "print(f'Latent shape: {encoded.shape}')\n",
    "print(f'Decoded shape: {decoded.shape}')\n",
    "\n",
    "assert x.shape == decoded.shape, 'Input and output shapes do not match!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "from model.ae import ConvEncoder\n",
    "\n",
    "summary(ConvEncoder(), (1, IMAGE_SIZE, IMAGE_SIZE), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarize_model(ConvEncoder()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarize_model([encoder, decoder]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dict = BatchSizeDict(\n",
    "    {'train': BATCH_SIZE, 'valid': BATCH_SIZE, 'test': BATCH_SIZE}\n",
    ")\n",
    "\n",
    "train_val_dataset = TemporalAutoencoderDataset(\n",
    "    memory_map_file=NORMAL_MEMORY_MAP,\n",
    "    memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    ")\n",
    "test_dataset = TemporalAutoencoderDataset(\n",
    "    memory_map_file=ANOMAL_MEMORY_MAP,\n",
    "    memory_map_image_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    ")\n",
    "\n",
    "# Train validation split\n",
    "train_size = int(TRAIN_SET_RATIO * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size_dict['train'],\n",
    "    shuffle=True,\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size_dict['valid'],\n",
    "    shuffle=False,\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size_dict['test'],\n",
    "    shuffle=False,\n",
    "    num_workers=int(os.cpu_count()),  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TemporalAutoencoderModel(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    batch_size_dict=batch_size_dict,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    loss_function=LOSS_FUNCTION,\n",
    "    train_noise_std_input=TRAIN_NOISE_STD_INPUT,\n",
    "    train_noise_std_latent=TRAIN_NOISE_STD_LATENT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(LOG_DIR, name=EXPERIMENT_NAME, version=VERSION)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=MONITOR,\n",
    "    mode='min',\n",
    "    patience=PATIENCE,\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=EXPERIMENT_DIR,\n",
    "    filename='{epoch}-{val_loss:3f}',\n",
    "    monitor=MONITOR,\n",
    "    save_top_k=1,  # save only the best model\n",
    "    mode='min',\n",
    ")\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',\n",
    "    logger=csv_logger,\n",
    "    callbacks=[model_checkpoint, early_stopping, progress_bar],\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    log_every_n_steps=1,  # log every batch\n",
    "    # https://lightning.ai/docs/pytorch/stable/common/trainer.html#reproducibility\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Load from MLflow\n",
    "    model_name = 'pytorch-2024-10-14-220152-anomaly-detection-conv-ae'\n",
    "    model_version = 1\n",
    "    model_uri = f'models:/{model_name}/{model_version}'\n",
    "    model_ = mlflow.pytorch.load_model(model_uri)\n",
    "else:\n",
    "    model_checkpoint_path = list(EXPERIMENT_DIR.glob('*.ckpt'))[0]\n",
    "    model_ = AutoencoderModel.load_from_checkpoint(\n",
    "        model_checkpoint_path, encoder=encoder, decoder=decoder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ = L.Trainer(logger=False)  # no need to log anything for validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = trainer_.validate(model_, dataloaders=valid_dataloader, verbose=False)[\n",
    "    0\n",
    "]\n",
    "pprint(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer_.test(model_, dataloaders=test_dataloader, verbose=False)[0]\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = Anomalies.from_file(ANOMALIES_FILE)\n",
    "n_test_frames = len(list((ANOMALIES_FILE.parent / 'images').glob('*.jpg')))\n",
    "y_true = anomalies.to_ground_truth(n_test_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_slice = test_dataset[anomalies[0].middle() // TIME_STEPS]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# plot_autoencoder_reconstruction(\n",
    "#     model_,\n",
    "#     test_dataloader,\n",
    "#     dataset_path=DATASET_DIR,\n",
    "#     save_path=EXPERIMENT_DIR / PREDICTIONS_PNG_NAME,\n",
    "#     limit=15,\n",
    "#     random_shuffle=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(\n",
    "    EXPERIMENT_DIR / METRICS_CSV_NAME,\n",
    "    save_path=EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME,\n",
    "    metrics={\n",
    "        'mse': 'Mean Squared Error',\n",
    "        'fro': 'Frobenius Norm',\n",
    "        'mae': 'Mean Absolute Error',\n",
    "    },\n",
    "    figsize=(22, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_stopping_epoch() -> int | None:\n",
    "    checkpoint = list(EXPERIMENT_DIR.glob('*.ckpt'))[0].stem\n",
    "    pattern = r'epoch=(\\d+)'\n",
    "    match = re.search(pattern, checkpoint)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dict_to_mlflow(\n",
    "    dictionary: Mapping[str, int | float], type: Literal['metric', 'param']\n",
    ") -> None:\n",
    "    for k, v in dictionary.items():\n",
    "        if type == 'metric':\n",
    "            mlflow.log_metric(k, v)\n",
    "        elif type == 'param':\n",
    "            mlflow.log_param(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submodule_param_count(model: L.LightningModule) -> dict[str, int]:\n",
    "    \"\"\"Get the number of parameters for each submodule in the model.\"\"\"\n",
    "    param_counts = {}\n",
    "    for name, submodule in model.named_children():\n",
    "        num_params = sum(p.numel() for p in submodule.parameters())\n",
    "        if num_params > 0:\n",
    "            param_counts[f'{name}_parameters'] = num_params\n",
    "    param_counts['total_parameters'] = sum([x for x in param_counts.values()])\n",
    "    return param_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f'{EXPERIMENT_NAME}') as run:\n",
    "    try:\n",
    "        mlflow.set_tag('Branch', get_current_branch())\n",
    "        mlflow.set_tag('Commit ID', get_commit_id())\n",
    "        mlflow.set_tag('Dataset', DATASET_NAME)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    log_dict_to_mlflow(valid_metrics, 'metric')\n",
    "    log_dict_to_mlflow(test_metrics, 'metric')\n",
    "    log_dict_to_mlflow(get_submodule_param_count(model_), 'param')\n",
    "\n",
    "    mlflow.log_param('encoder', str(encoder))\n",
    "    mlflow.log_param('decoder', str(decoder))\n",
    "    mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "    mlflow.log_param('max_epochs', MAX_EPOCHS)\n",
    "    mlflow.log_param('early_stopping', get_early_stopping_epoch())\n",
    "    mlflow.log_param('monitor', MONITOR)\n",
    "    mlflow.log_param('patience', PATIENCE)\n",
    "    mlflow.log_param('image_size', IMAGE_SIZE)\n",
    "    mlflow.log_param('learning_rate', LEARNING_RATE)\n",
    "    mlflow.log_param('loss_function', LOSS_FUNCTION)\n",
    "    mlflow.log_param('train_noise_std_input', TRAIN_NOISE_STD_INPUT)\n",
    "    mlflow.log_param('train_noise_std_latent', TRAIN_NOISE_STD_LATENT)\n",
    "    mlflow.log_param('seed', SEED)\n",
    "    mlflow.log_param('time_steps', TIME_STEPS)\n",
    "    mlflow.log_param('train_set_ratio', TRAIN_SET_RATIO)\n",
    "\n",
    "    mlflow.log_artifact(str(EXPERIMENT_DIR / METRICS_CSV_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(\n",
    "        str(EXPERIMENT_DIR / LEARNING_CURVES_PDF_NAME), MLFLOW_ARTIFACT_DIR\n",
    "    )\n",
    "    # TODO: mlflow.log_artifact(str(EXPERIMENT_DIR / PREDICTIONS_PNG_NAME), MLFLOW_ARTIFACT_DIR)\n",
    "    mlflow.log_artifact(NOTEBOOK_NAME, MLFLOW_ARTIFACT_DIR)\n",
    "\n",
    "    input = np.random.random((BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE))\n",
    "    signature = mlflow.models.infer_signature(input, input, dict(training=False))  # type: ignore\n",
    "\n",
    "    # Models are versioned by default\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model_,\n",
    "        artifact_path='model',\n",
    "        registered_model_name=f'pytorch-{EXPERIMENT_NAME}',\n",
    "        signature=signature,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
